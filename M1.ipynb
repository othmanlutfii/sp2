{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader.data import DataReader\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = \"BBRI\"\n",
    "comp = comp+\".JK\"\n",
    "end = datetime.now()\n",
    "start = datetime(end.year - 5, end.month, end.day)\n",
    "comp_dat = yf.download(comp, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = [comp_dat]\n",
    "company_name = [comp]\n",
    "\n",
    "for company, com_name in zip(company_list, company_name):\n",
    "    company[\"company_name\"] = com_name\n",
    "    \n",
    "df = pd.concat(company_list, axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the 'Close column \n",
    "data = df.filter(['Close'])\n",
    "# Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_len = int(np.ceil( len(dataset) * .80 ))\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the prices between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_prices = scaler.fit_transform(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_size = int(len(scaled_prices) * 0.8)-30\n",
    "train_data = scaled_prices[:train_size]\n",
    "test_data = scaled_prices[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length-1):\n",
    "        X.append(data[i : i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 30  # Number of previous days' prices to use as input features\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the models predicted price values \n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the testing data set\n",
    "\n",
    "# Get the root mean squared error (RMSE)\n",
    "rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = data[train_size+seq_length+1:]\n",
    "valid['Predictions'] = predictions\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "valid['Predictions'] = predictions\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend([ 'Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Make predictions for the next 7 days\n",
    "last_sequence = test_data[-seq_length:]  # Last sequence from the testing data\n",
    "\n",
    "predicted_prices = []\n",
    "\n",
    "harga_kedepan = []\n",
    "\n",
    "banyak_prediksi= 7\n",
    "for _ in range(banyak_prediksi):\n",
    "    next_price = model.predict(last_sequence.reshape(1, seq_length, 1))\n",
    "    predicted_prices.append(next_price)\n",
    "    print(next_price)\n",
    "    last_sequence = np.append(last_sequence[1:], next_price)\n",
    "    harga_kedepan.append(next_price)\n",
    "\n",
    "\n",
    "\n",
    "# Inverse transform the predicted prices to the original scale\n",
    "predicted_prices = scaler.inverse_transform(np.array(predicted_prices).reshape(-1, 1))\n",
    "\n",
    "# Print the predicted prices for the next 7 days\n",
    "# print(\"Predicted Prices for the Next 7 Days:\")\n",
    "# for price in predicted_prices:\n",
    "#     print(price[0])\n",
    "\n",
    "print(harga_kedepan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Make predictions for the next 7 days\n",
    "last_sequence = test_data[-seq_length:]  # Last sequence from the testing data\n",
    "predicted_prices = []\n",
    "harga_lstm = []\n",
    "\n",
    "banyak_prediksi = 7\n",
    "for _ in range(banyak_prediksi):\n",
    "    next_price = model.predict(last_sequence.reshape(1, seq_length, 1))\n",
    "    predicted_prices.append(next_price)\n",
    "    last_sequence = np.append(last_sequence[1:], next_price)\n",
    "\n",
    "\n",
    "\n",
    "    # Inverse transform the predicted prices to the original scale\n",
    "predicted_prices = scaler.inverse_transform(np.array(predicted_prices).reshape(-1, 1))\n",
    "\n",
    "    # Print the predicted prices for the next 7 days\n",
    "for price in predicted_prices:\n",
    "    harga_pred = price[0]\n",
    "    harga_lstm.append(harga_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harga_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader.data import DataReader\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def prediksi_lstm(df,lama_pred):\n",
    "\n",
    "    data = df.copy()\n",
    "    # Create a new dataframe with only the 'Close column \n",
    "    data = data.filter(['Close'])\n",
    "    # Convert the dataframe to a numpy array\n",
    "    dataset = data.values\n",
    "    # Get the number of rows to train the model on\n",
    "    training_data_len = int(np.ceil( len(dataset) * .80 ))-30\n",
    "    # Normalize the prices between 0 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_prices = scaler.fit_transform(dataset)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_size = int(len(scaled_prices) * 0.8)\n",
    "    train_data = scaled_prices[:train_size]\n",
    "    test_data = scaled_prices[train_size:]\n",
    "\n",
    "    # Step 2: Create sequences\n",
    "    def create_sequences(data, seq_length):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - seq_length-1):\n",
    "            X.append(data[i : i + seq_length])\n",
    "            y.append(data[i + seq_length])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    seq_length = 30  # Number of previous days' prices to use as input features\n",
    "    X_train, y_train = create_sequences(train_data, seq_length)\n",
    "    X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, batch_size=1, epochs=2)\n",
    "\n",
    "    # Get the models predicted price values \n",
    "    predictions_lstm = []\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "    for i in predictions:\n",
    "        pred_each= i[0]\n",
    "        predictions_lstm.append(pred_each)\n",
    "\n",
    "\n",
    "    # Step 6: Make predictions for the next 7 days\n",
    "    last_sequence = test_data[-seq_length:]  # Last sequence from the testing data\n",
    "    predicted_prices = []\n",
    "    harga_lstm = []\n",
    "\n",
    "    banyak_prediksi = lama_pred\n",
    "    for _ in range(banyak_prediksi):\n",
    "        next_price = model.predict(last_sequence.reshape(1, seq_length, 1))\n",
    "        predicted_prices.append(next_price)\n",
    "        last_sequence = np.append(last_sequence[1:], next_price)\n",
    "\n",
    "\n",
    "\n",
    "    # Inverse transform the predicted prices to the original scale\n",
    "    predicted_prices = scaler.inverse_transform(np.array(predicted_prices).reshape(-1, 1))\n",
    "\n",
    "    # Print the predicted prices for the next 7 days\n",
    "    for price in predicted_prices:\n",
    "        harga_pred = price[0]\n",
    "        harga_lstm.append(harga_pred)\n",
    "\n",
    "        \n",
    "\n",
    "    return(harga_lstm,predictions_lstm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-04</th>\n",
       "      <td>3150.0</td>\n",
       "      <td>3170.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>2594.125000</td>\n",
       "      <td>211936400</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-05</th>\n",
       "      <td>3150.0</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>2577.549561</td>\n",
       "      <td>135979600</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-06</th>\n",
       "      <td>3120.0</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>2610.701172</td>\n",
       "      <td>99509500</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07</th>\n",
       "      <td>3180.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>2710.156250</td>\n",
       "      <td>183746200</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-08</th>\n",
       "      <td>3210.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>2602.413086</td>\n",
       "      <td>262972300</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-25</th>\n",
       "      <td>5500.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>5450.0</td>\n",
       "      <td>5475.0</td>\n",
       "      <td>5475.000000</td>\n",
       "      <td>224391900</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-26</th>\n",
       "      <td>5425.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>5425.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>5600.000000</td>\n",
       "      <td>154003100</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-29</th>\n",
       "      <td>5600.0</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>5475.0</td>\n",
       "      <td>5550.0</td>\n",
       "      <td>5550.000000</td>\n",
       "      <td>125049100</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-30</th>\n",
       "      <td>5500.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>67363200</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31</th>\n",
       "      <td>5575.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>5375.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>5575.000000</td>\n",
       "      <td>898453700</td>\n",
       "      <td>BBRI.JK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close    Adj Close     Volume   \n",
       "Date                                                                 \n",
       "2018-06-04  3150.0  3170.0  3100.0  3130.0  2594.125000  211936400  \\\n",
       "2018-06-05  3150.0  3160.0  3090.0  3110.0  2577.549561  135979600   \n",
       "2018-06-06  3120.0  3160.0  3090.0  3150.0  2610.701172   99509500   \n",
       "2018-06-07  3180.0  3270.0  3160.0  3270.0  2710.156250  183746200   \n",
       "2018-06-08  3210.0  3250.0  3110.0  3140.0  2602.413086  262972300   \n",
       "...            ...     ...     ...     ...          ...        ...   \n",
       "2023-05-25  5500.0  5575.0  5450.0  5475.0  5475.000000  224391900   \n",
       "2023-05-26  5425.0  5600.0  5425.0  5600.0  5600.000000  154003100   \n",
       "2023-05-29  5600.0  5625.0  5475.0  5550.0  5550.000000  125049100   \n",
       "2023-05-30  5500.0  5600.0  5500.0  5500.0  5500.000000   67363200   \n",
       "2023-05-31  5575.0  5575.0  5375.0  5575.0  5575.000000  898453700   \n",
       "\n",
       "           company_name  \n",
       "Date                     \n",
       "2018-06-04      BBRI.JK  \n",
       "2018-06-05      BBRI.JK  \n",
       "2018-06-06      BBRI.JK  \n",
       "2018-06-07      BBRI.JK  \n",
       "2018-06-08      BBRI.JK  \n",
       "...                 ...  \n",
       "2023-05-25      BBRI.JK  \n",
       "2023-05-26      BBRI.JK  \n",
       "2023-05-29      BBRI.JK  \n",
       "2023-05-30      BBRI.JK  \n",
       "2023-05-31      BBRI.JK  \n",
       "\n",
       "[1240 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scrap_data\n",
    "data_saham = scrap_data.ambil_data(\"bbri\")\n",
    "\n",
    "data_saham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "961/961 [==============================] - 14s 12ms/step - loss: 0.0036\n",
      "Epoch 2/2\n",
      "961/961 [==============================] - 11s 12ms/step - loss: 0.0016\n",
      "7/7 [==============================] - 1s 12ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5585.2456, 5611.879, 5646.775, 5688.398, 5735.7837, 5787.943, 5843.831],\n",
       " [4160.0107,\n",
       "  4131.556,\n",
       "  4140.2036,\n",
       "  4171.2207,\n",
       "  4178.034,\n",
       "  4281.0957,\n",
       "  4365.663,\n",
       "  4381.909,\n",
       "  4357.124,\n",
       "  4372.7944,\n",
       "  4381.3545,\n",
       "  4404.8047,\n",
       "  4419.1064,\n",
       "  4423.027,\n",
       "  4443.7344,\n",
       "  4446.132,\n",
       "  4430.6675,\n",
       "  4417.1035,\n",
       "  4415.6704,\n",
       "  4441.1484,\n",
       "  4405.1943,\n",
       "  4394.5376,\n",
       "  4377.9966,\n",
       "  4357.8696,\n",
       "  4336.3955,\n",
       "  4354.4634,\n",
       "  4358.687,\n",
       "  4342.34,\n",
       "  4345.933,\n",
       "  4347.3604,\n",
       "  4336.915,\n",
       "  4328.582,\n",
       "  4313.4956,\n",
       "  4309.798,\n",
       "  4356.211,\n",
       "  4422.49,\n",
       "  4496.9316,\n",
       "  4616.717,\n",
       "  4668.9062,\n",
       "  4615.2466,\n",
       "  4634.608,\n",
       "  4661.421,\n",
       "  4645.4116,\n",
       "  4636.0967,\n",
       "  4630.866,\n",
       "  4646.315,\n",
       "  4595.699,\n",
       "  4595.094,\n",
       "  4560.93,\n",
       "  4572.298,\n",
       "  4596.817,\n",
       "  4568.7754,\n",
       "  4577.3647,\n",
       "  4584.921,\n",
       "  4583.7686,\n",
       "  4558.108,\n",
       "  4544.514,\n",
       "  4563.533,\n",
       "  4646.168,\n",
       "  4646.9062,\n",
       "  4609.347,\n",
       "  4537.0093,\n",
       "  4449.366,\n",
       "  4434.9097,\n",
       "  4431.31,\n",
       "  4408.8213,\n",
       "  4350.944,\n",
       "  4331.601,\n",
       "  4328.084,\n",
       "  4339.581,\n",
       "  4403.2227,\n",
       "  4474.379,\n",
       "  4553.8906,\n",
       "  4646.6934,\n",
       "  4658.165,\n",
       "  4678.0864,\n",
       "  4700.0186,\n",
       "  4717.85,\n",
       "  4727.336,\n",
       "  4697.2227,\n",
       "  4693.042,\n",
       "  4695.505,\n",
       "  4722.247,\n",
       "  4701.2446,\n",
       "  4697.2026,\n",
       "  4628.804,\n",
       "  4649.3525,\n",
       "  4641.5933,\n",
       "  4634.094,\n",
       "  4596.7935,\n",
       "  4659.175,\n",
       "  4681.614,\n",
       "  4673.529,\n",
       "  4660.6787,\n",
       "  4698.1562,\n",
       "  4758.149,\n",
       "  4811.4854,\n",
       "  4876.387,\n",
       "  4925.878,\n",
       "  5020.2847,\n",
       "  5047.8354,\n",
       "  5009.2095,\n",
       "  4967.0986,\n",
       "  4922.034,\n",
       "  4837.6714,\n",
       "  4835.3574,\n",
       "  4832.8486,\n",
       "  4867.058,\n",
       "  4969.019,\n",
       "  5044.72,\n",
       "  5033.3276,\n",
       "  5045.33,\n",
       "  5045.0234,\n",
       "  5002.3174,\n",
       "  4956.694,\n",
       "  4974.341,\n",
       "  4950.596,\n",
       "  4961.7886,\n",
       "  4940.433,\n",
       "  4893.9893,\n",
       "  4895.961,\n",
       "  4952.18,\n",
       "  4953.5146,\n",
       "  4930.581,\n",
       "  4864.3013,\n",
       "  4743.339,\n",
       "  4658.903,\n",
       "  4610.604,\n",
       "  4508.638,\n",
       "  4422.5737,\n",
       "  4457.5864,\n",
       "  4502.376,\n",
       "  4559.2373,\n",
       "  4618.183,\n",
       "  4672.344,\n",
       "  4701.992,\n",
       "  4729.8906,\n",
       "  4720.5054,\n",
       "  4666.544,\n",
       "  4641.3813,\n",
       "  4662.333,\n",
       "  4667.2896,\n",
       "  4649.692,\n",
       "  4693.9004,\n",
       "  4684.782,\n",
       "  4756.052,\n",
       "  4804.7964,\n",
       "  4829.2886,\n",
       "  4856.204,\n",
       "  4878.23,\n",
       "  4914.398,\n",
       "  4896.5186,\n",
       "  4913.5737,\n",
       "  4927.237,\n",
       "  4932.016,\n",
       "  4936.9395,\n",
       "  4938.2407,\n",
       "  4901.2705,\n",
       "  4837.631,\n",
       "  4823.523,\n",
       "  4806.26,\n",
       "  4830.452,\n",
       "  4772.3574,\n",
       "  4755.9688,\n",
       "  4794.27,\n",
       "  4817.7666,\n",
       "  4846.0435,\n",
       "  4890.9175,\n",
       "  4916.019,\n",
       "  4903.5503,\n",
       "  4890.9746,\n",
       "  4887.4863,\n",
       "  4814.799,\n",
       "  4755.796,\n",
       "  4747.3115,\n",
       "  4859.4976,\n",
       "  4937.4155,\n",
       "  4982.6665,\n",
       "  4916.2476,\n",
       "  4834.2876,\n",
       "  4803.04,\n",
       "  4823.109,\n",
       "  4812.7534,\n",
       "  4791.537,\n",
       "  4821.2646,\n",
       "  4861.8223,\n",
       "  4892.3354,\n",
       "  4910.797,\n",
       "  4927.167,\n",
       "  4944.266,\n",
       "  4980.534,\n",
       "  5030.89,\n",
       "  5114.466,\n",
       "  5108.106,\n",
       "  5055.2334,\n",
       "  5058.299,\n",
       "  5146.2905,\n",
       "  5178.527,\n",
       "  5211.5537,\n",
       "  5193.213,\n",
       "  5199.9004,\n",
       "  5252.091,\n",
       "  5209.068,\n",
       "  5180.85,\n",
       "  5183.731,\n",
       "  5192.906,\n",
       "  5200.396,\n",
       "  5204.66,\n",
       "  5237.3765,\n",
       "  5259.7334,\n",
       "  5392.785,\n",
       "  5495.9604,\n",
       "  5582.46,\n",
       "  5674.9766,\n",
       "  5629.1177,\n",
       "  5646.744,\n",
       "  5626.7944])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_lstm\n",
    "\n",
    "prediksi = prediksi_lstm(data_saham,7)\n",
    "\n",
    "prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5585.2456, 5611.879, 5646.775, 5688.398, 5735.7837, 5787.943, 5843.831]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediksi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader.data import DataReader\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def prediksi_lstm(df,lama_pred):\n",
    "\n",
    "    data = df.copy()\n",
    "    # Create a new dataframe with only the 'Close column \n",
    "    data = data.filter(['Close'])\n",
    "    # Convert the dataframe to a numpy array\n",
    "    dataset = data.values\n",
    "    # Get the number of rows to train the model on\n",
    "    training_data_len = int(np.ceil( len(dataset) * .80 ))\n",
    "    # Normalize the prices between 0 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_prices = scaler.fit_transform(dataset)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_size = int(len(scaled_prices) * 0.8) - 30\n",
    "    train_data = scaled_prices[:train_size]\n",
    "    test_data = scaled_prices[train_size:]\n",
    "\n",
    "    # Step 2: Create sequences\n",
    "    def create_sequences(data, seq_length):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - seq_length-1):\n",
    "            X.append(data[i : i + seq_length])\n",
    "            y.append(data[i + seq_length])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    seq_length = 30  # Number of previous days' prices to use as input features\n",
    "    X_train, y_train = create_sequences(train_data, seq_length)\n",
    "    X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, batch_size=1, epochs=2)\n",
    "\n",
    "    # Get the models predicted price values \n",
    "    predictions_lstm = []\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "    for i in predictions:\n",
    "        pred_each= i[0]\n",
    "        predictions_lstm.append(pred_each)\n",
    "\n",
    "\n",
    "    # Step 6: Make predictions for the next 7 days\n",
    "    last_sequence = test_data[-seq_length:]  # Last sequence from the testing data\n",
    "    predicted_prices = []\n",
    "    harga_kedepan = []\n",
    "\n",
    "    banyak_prediksi = lama_pred\n",
    "    for _ in range(banyak_prediksi):\n",
    "        next_price = model.predict(last_sequence.reshape(1, seq_length, 1))\n",
    "        predicted_prices.append(next_price)\n",
    "        last_sequence = np.append(last_sequence[1:], next_price)\n",
    "\n",
    "\n",
    "\n",
    "    # Inverse transform the predicted prices to the original scale\n",
    "    predicted_prices = scaler.inverse_transform(np.array(predicted_prices).reshape(-1, 1))\n",
    "\n",
    "    # Print the predicted prices for the next 7 days\n",
    "    for price in predicted_prices:\n",
    "        harga_pred = price[0]\n",
    "        harga_kedepan.append(harga_pred)\n",
    "\n",
    "        \n",
    "\n",
    "    return(harga_kedepan,predictions_lstm)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
